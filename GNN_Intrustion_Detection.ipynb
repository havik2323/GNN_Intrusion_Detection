{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c41a2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.nn import GraphConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch.nn import functional as F\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db611738",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eac9fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UNSW-NB15.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb47e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the first few rows of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Get summary statistics for numeric columns\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check data types of each column\n",
    "print(df.dtypes)\n",
    "\n",
    "# Count of each type in 'Label' column (assuming this is a categorical variable)\n",
    "print(df['Label'].value_counts())\n",
    "\n",
    "# Histograms for numerical columns\n",
    "num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "for col in num_cols:\n",
    "    df[col].hist()\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "# Box plots for numerical columns\n",
    "for col in num_cols:\n",
    "    df.boxplot(column=col)\n",
    "    plt.title(col)\n",
    "    plt.show()\n",
    "\n",
    "# For categorical columns, we can use count plots\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "elements_to_remove = ['srcip', 'dstip', 'sport', 'dsport']\n",
    "cat_cols = [col for col in cat_cols if col not in elements_to_remove]\n",
    "\n",
    "for col in cat_cols:\n",
    "    sns.countplot(data=df, x=col)\n",
    "    plt.title(col)\n",
    "    plt.xticks(rotation=90)  # makes labels readable\n",
    "    plt.show()\n",
    "\n",
    "# Correlation heatmap for numerical columns\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.heatmap(df[num_cols].corr(), annot=True, fmt=\".2f\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0228662d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['dur', 'sbytes', 'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'Sload',\n",
    "                  'Dload', 'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz',\n",
    "                  'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime', 'Ltime',\n",
    "                  'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
    "                  'ct_state_ttl', 'ct_flw_http_mthd', 'ct_ftp_cmd',\n",
    "                  'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm', 'ct_src_dport_ltm',\n",
    "                  'ct_dst_sport_ltm', 'ct_dst_src_ltm']\n",
    "df[numerical_cols] = df[numerical_cols].apply(pd.to_numeric, errors='coerce')\n",
    "categorical_cols = ['proto', 'state', 'service']\n",
    "df[categorical_cols] = df[categorical_cols].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9fdd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['attack_cat'] = df['attack_cat'].replace(np.NaN, 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd29e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.get_dummies(df, columns=categorical_cols)\n",
    "scaler = StandardScaler()\n",
    "df[numerical_cols] = scaler.fit_transform(df[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98804a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ip_to_binary(df, column_name, new_column_name):\n",
    "    temp = pd.DataFrame()\n",
    "    temp[column_name] = df[column_name].astype(str)\n",
    "    temp[column_name][~temp[column_name].str.contains('\\d{1,3}\\.', regex=True)] = '0.0.0.0'\n",
    "    temp = temp[column_name].str.split('.', expand=True).rename(columns = {2: f'{new_column_name}3', 3: f'{new_column_name}4'}).astype(int)[[f'{new_column_name}3', f'{new_column_name}4']]\n",
    "    temp[new_column_name] = temp[f'{new_column_name}3'].apply(lambda x: format(x, \"b\").zfill(8)) + temp[f'{new_column_name}4'].apply(lambda x: format(x, \"b\").zfill(8))\n",
    "    \n",
    "    split_binary = temp[new_column_name].str.split('', expand=True)\n",
    "    split_binary.drop(columns=[0, 17], inplace=True)\n",
    "    split_binary.columns = [f'{new_column_name}_{i}' for i in range(16)]\n",
    "    split_binary = split_binary.astype('int32')\n",
    "\n",
    "    df = df.join(split_binary)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc1d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ip_to_binary(df, 'srcip', 'ipsrc')\n",
    "df = ip_to_binary(df, 'dstip', 'ipdst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb2b776",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df['attack_cat_encoded'] = label_encoder.fit_transform(df['attack_cat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7fce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_exclude = ['attack_cat', 'Label', 'attack_cat_encoded',\n",
    "                      'sport', 'dsport', 'proto', 'state', 'srcip', 'dstip', 'service', 'ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd']\n",
    "all_columns = df.columns.to_list()\n",
    "columns_array = [col for col in all_columns if col not in columns_to_exclude]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89245524",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['attack_cat', \"Label\", 'dsport', 'sport','ct_flw_http_mthd', 'is_ftp_login', 'ct_ftp_cmd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcea13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, random_state=0, test_size=0.2, stratify=df['attack_cat_encoded'])\n",
    "df_val, df_test = train_test_split(df_test, random_state=0, test_size=0.5, stratify=df_test['attack_cat_encoded'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f636e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "####IMPLEMENT GNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d7b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "features_host = [f'ipsrc_{i}' for i in range(0, 16)] + [f'ipdst_{i}' for i in range(0, 16)]\n",
    "features_flow = columns_array\n",
    "\n",
    "def get_connections(ip_map, src_ip, dst_ip):\n",
    "    src1 = [ip_map[ip] for ip in src_ip]\n",
    "    src2 = [ip_map[ip] for ip in dst_ip]\n",
    "    src = np.column_stack((src1, src2)).flatten()\n",
    "    dst = list(range(len(src_ip)))\n",
    "    dst = np.column_stack((dst, dst)).flatten()\n",
    "    \n",
    "    return torch.Tensor([src, dst]).int(), torch.Tensor([dst, src]).int()\n",
    "\n",
    "def create_dataloader(df, subgraph_size=1024):\n",
    "    data = []\n",
    "    n_subgraphs = len(df) // subgraph_size\n",
    "    for i in range(1, n_subgraphs+1):\n",
    "        subgraph = df[(i-1)*subgraph_size:i*subgraph_size]\n",
    "        src_ip = subgraph['srcip'].to_numpy()\n",
    "        dst_ip = subgraph['dstip'].to_numpy()\n",
    "        \n",
    "        ip_map = {ip:index for index, ip in enumerate(np.unique(np.append(src_ip, dst_ip)))}\n",
    "        host_to_flow, flow_to_host = get_connections(ip_map, src_ip, dst_ip)\n",
    "        \n",
    "        batch = HeteroData()\n",
    "        batch['host'].x = torch.Tensor(subgraph[features_host].to_numpy()).float()\n",
    "        batch['flow'].x = torch.Tensor(subgraph[features_flow].to_numpy()).float()\n",
    "        batch['flow'].y = torch.Tensor(subgraph['attack_cat_encoded'].to_numpy()).long()\n",
    "        batch['host','flow'].edge_index = host_to_flow\n",
    "        batch['flow','host'].edge_index = flow_to_host\n",
    "        data.append(batch)\n",
    "        \n",
    "    return DataLoader(data, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "train_loader = create_dataloader(df_train)\n",
    "val_loader = create_dataloader(df_val)\n",
    "test_loader = create_dataloader(df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bfbddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeteroGNN(torch.nn.Module):\n",
    "    def __init__(self, in_channels_host, in_channels_flow, hidden_channels, out_channels):\n",
    "        super(HeteroGNN, self).__init__()\n",
    "\n",
    "        self.conv_host = GraphConv(in_channels_host, hidden_channels)\n",
    "        self.conv_flow = GraphConv(in_channels_flow, hidden_channels)\n",
    "        self.fc = torch.nn.Linear(2*hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x_host = F.relu(self.conv_host(data['host'].x, data['host','flow'].edge_index))\n",
    "        x_flow = F.relu(self.conv_flow(data['flow'].x, data['flow','host'].edge_index))\n",
    "        x = torch.cat([x_host, x_flow], dim=-1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return F.log_softmax(x, dim=-1)\n",
    "\n",
    "# Parameters\n",
    "in_channels_host = len(features_host)\n",
    "in_channels_flow = len(features_flow)\n",
    "hidden_channels = 32  # choose as needed\n",
    "out_channels = 14 # the number of classes\n",
    "learning_rate = 0.01\n",
    "num_epochs = 100\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Model Initialization\n",
    "model = HeteroGNN(in_channels_host, in_channels_flow, hidden_channels, out_channels).to(device)\n",
    "\n",
    "# Optimizer Initialization\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=10, factor=0.5)\n",
    "torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n",
    "# Training Function\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(batch)\n",
    "        loss = F.cross_entropy(out, batch['flow'].y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    preds, targets = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(batch)\n",
    "        pred = out.argmax(dim=1)\n",
    "        preds.extend(pred.tolist())\n",
    "        targets.extend(batch['flow'].y.tolist())\n",
    "    accuracy = (np.array(preds) == np.array(targets)).mean()\n",
    "    return accuracy, preds, targets\n",
    "\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train()\n",
    "    train_acc, _, _ = test(train_loader)\n",
    "    val_acc, val_preds, val_targets = test(val_loader)\n",
    "    val_prec = precision_score(val_targets, val_preds, average='micro')\n",
    "    val_recall = recall_score(val_targets, val_preds, average='micro')\n",
    "    print(f'Epoch: {epoch+1}, Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, Val Acc: {val_acc:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n",
    "    # Step with the scheduler\n",
    "    scheduler.step(train_loss)    \n",
    "    \n",
    "\n",
    "# Testing\n",
    "val_acc, val_preds, val_targets = test(val_loader)\n",
    "val_prec = precision_score(val_targets, val_preds, average='micro')\n",
    "val_recall = recall_score(val_targets, val_preds, average='micro')\n",
    "print(f'Epoch: {epoch+1}, Test Acc: {val_acc:.4f}, Val Precision: {val_prec:.4f}, Val Recall: {val_recall:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23dc66b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd4a832",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17540c3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_env",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
